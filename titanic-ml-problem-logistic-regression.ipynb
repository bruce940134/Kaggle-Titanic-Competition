{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport scipy.optimize as op\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T23:27:04.423523Z","iopub.execute_input":"2022-03-10T23:27:04.423853Z","iopub.status.idle":"2022-03-10T23:27:05.014359Z","shell.execute_reply.started":"2022-03-10T23:27:04.423772Z","shell.execute_reply":"2022-03-10T23:27:05.013438Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Pre-process data\ntrain_data = pd.read_csv(\"../input/titanic/train.csv\")\ntest_data = pd.read_csv(\"../input/titanic/test.csv\")\n# Decide feature parameters\n# Initial decision: Pclass, Age, SibSp, Parch, Fare\ntrain_data = train_data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\ntrain_data = train_data.dropna(axis=0)\ntest_data = test_data[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\ntrain_X = train_data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\ntrain_y = train_data[['Survived']]\n# Converting dataframe to numpy array\nX_train = train_X.to_numpy()\ny_train = train_y.to_numpy()\nX_test = test_data.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.015867Z","iopub.execute_input":"2022-03-10T23:27:05.016118Z","iopub.status.idle":"2022-03-10T23:27:05.057482Z","shell.execute_reply.started":"2022-03-10T23:27:05.016089Z","shell.execute_reply":"2022-03-10T23:27:05.056816Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define sigmoid function\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.058458Z","iopub.execute_input":"2022-03-10T23:27:05.059065Z","iopub.status.idle":"2022-03-10T23:27:05.062646Z","shell.execute_reply.started":"2022-03-10T23:27:05.059014Z","shell.execute_reply":"2022-03-10T23:27:05.061879Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Define function for feature normalization (X is the feature matrix)\n# Function returns a normalized version of X where the mean value of\n# each feature is 0 and the standard deviation is 1.\ndef feature_normalization(X):\n    X_norm = X\n    mean = X.mean(axis=0)\n    X_norm = X_norm - mean\n    sigma = np.std(X_norm, axis=0)\n    X_norm = np.divide(X_norm, sigma)\n    return X_norm","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.064344Z","iopub.execute_input":"2022-03-10T23:27:05.064816Z","iopub.status.idle":"2022-03-10T23:27:05.076136Z","shell.execute_reply.started":"2022-03-10T23:27:05.064770Z","shell.execute_reply":"2022-03-10T23:27:05.075210Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Define regularized cost function\ndef costFunction(theta, X, y, reglambda):\n    m = np.shape(y)[0]\n    h = sigmoid(X*theta)\n    J = (-y)*np.log(h) - (1-y)*np.log(1-h)\n    J = np.sum(J) / m\n    t = theta\n    t[0] = 0\n    t = np.square(t)\n    J = J + (np.sum(t) * reglambda / (2*m))\n    return J","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.077243Z","iopub.execute_input":"2022-03-10T23:27:05.077707Z","iopub.status.idle":"2022-03-10T23:27:05.092530Z","shell.execute_reply.started":"2022-03-10T23:27:05.077655Z","shell.execute_reply":"2022-03-10T23:27:05.091671Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define gradient\ndef gradient(theta, X, y, reglambda):\n    m = np.shape(y)[0]\n    h = sigmoid(X*theta)\n    h = (h - y) * X\n    t = theta\n    t[0] = 0\n    h = np.sum(h, axis=0, keepdims=True) / m\n    h = h + (reglambda * t / m)\n    return h","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.093948Z","iopub.execute_input":"2022-03-10T23:27:05.094338Z","iopub.status.idle":"2022-03-10T23:27:05.104407Z","shell.execute_reply.started":"2022-03-10T23:27:05.094308Z","shell.execute_reply":"2022-03-10T23:27:05.103514Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define feature mapping function to create more training data\ndef featureMap(X1, X2):\n    degree = 6\n    out = np.ones((np.shape(X1)[0],1))\n    for i in (n+1 for n in range(degree)):\n        for j in range(i):\n            X_1 = np.power(X1, (i-j))\n            X_2 = np.power(X2, j)\n            newFeature = X_1 * X_2\n            newFeature = np.reshape(newFeature, (np.shape(X_1)[0],1))\n            out = np.hstack((out, newFeature))\n    return out[:,1:]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.105753Z","iopub.execute_input":"2022-03-10T23:27:05.106011Z","iopub.status.idle":"2022-03-10T23:27:05.116449Z","shell.execute_reply.started":"2022-03-10T23:27:05.105983Z","shell.execute_reply":"2022-03-10T23:27:05.115615Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Normalize training features\nX_norm = feature_normalization(X_train)\n# Perform feature mapping\n#X_norm = featureMap(X_norm[:,1],X_norm[:,2])\n# Add bias term\nbias = np.ones((np.shape(X_norm)[0],1))\nX_norm = np.hstack((bias, X_norm))\nreglambda = 10000\ninitial_theta = np.zeros((np.shape(X_norm)[1],1))\noptimal_theta = op.minimize(fun = costFunction, x0 = initial_theta,\n                         args = (X_norm, y_train, reglambda), method = 'BFGS').x\noptimal_theta = np.reshape(optimal_theta, (np.shape(optimal_theta)[0],1))\noptimal_theta = optimal_theta[1:]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.117775Z","iopub.execute_input":"2022-03-10T23:27:05.117982Z","iopub.status.idle":"2022-03-10T23:27:05.150847Z","shell.execute_reply.started":"2022-03-10T23:27:05.117956Z","shell.execute_reply":"2022-03-10T23:27:05.149955Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Define prediction function that takes unprocessed data X and theta\n# to produce prediction\ndef predict(X, theta):\n    pred = np.zeros((np.shape(X)[0],1))\n    s = np.matmul(X, theta)\n    for i in range(np.shape(pred)[0]):\n        if s[i] < 0.3:\n            pred[i] = 0\n        else:\n            pred[i] = 1\n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.152121Z","iopub.execute_input":"2022-03-10T23:27:05.152368Z","iopub.status.idle":"2022-03-10T23:27:05.158872Z","shell.execute_reply.started":"2022-03-10T23:27:05.152336Z","shell.execute_reply":"2022-03-10T23:27:05.157964Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"output = np.array(X_test[:,0])\noutput = np.reshape(output,(np.shape(output)[0],1))\nX_test = X_test[:,1:]\noutput = np.hstack((output,predict(X_test, optimal_theta)))\noutput_df = pd.DataFrame(output, columns = ['PassengerId', 'Survived'], dtype=int)\noutput_df.to_csv('output.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.161060Z","iopub.execute_input":"2022-03-10T23:27:05.161355Z","iopub.status.idle":"2022-03-10T23:27:05.177828Z","shell.execute_reply.started":"2022-03-10T23:27:05.161323Z","shell.execute_reply":"2022-03-10T23:27:05.177108Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Training accuracy\npred_train = predict(X_train, optimal_theta)\npred_train = pred_train + y_train\ntrue_true = (pred_train == 2).sum()\ntrue_false = (pred_train == 0).sum()\n(true_true + true_false) / np.shape(y_train)[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T23:27:05.178920Z","iopub.execute_input":"2022-03-10T23:27:05.179632Z","iopub.status.idle":"2022-03-10T23:27:05.191521Z","shell.execute_reply.started":"2022-03-10T23:27:05.179600Z","shell.execute_reply":"2022-03-10T23:27:05.190677Z"},"trusted":true},"execution_count":11,"outputs":[]}]}